{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd927211",
   "metadata": {},
   "source": [
    "# SkullGAN: Synthetic Skull CT Generation with Generative Adversarial Networks\n",
    "\n",
    "Paper: [KBP Lab](https://kbplab.stanford.edu/SkullGAN) <br>\n",
    "Code: [GitHub](https://github.com/kbp-lab/SkullGAN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa98c3bc-7cd8-4815-9d29-628beea5e95c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 1: Setup\n",
    "\n",
    "We start by importing all of the necessary packages from PyTorch, NumPy, and other libraries. We also define the training hyperparameters, as well as where to save any produced figures. Lastly, we create some useful functions for data normalization, and managing data transfer between our CPU and GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0091fdd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## -------------------------------- ##\n",
    "## IMPORT NECESSARY PACKAGES\n",
    "## -------------------------------- ##\n",
    "\n",
    "## ----- SYSTEM ----- ##\n",
    "import os\n",
    "import random\n",
    "\n",
    "## ----- STATS ----- ##\n",
    "import numpy as np\n",
    "\n",
    "## ----- TORCH ----- ##\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.utils as vutils\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "## ----- DISPLAY ----- ##\n",
    "from IPython import display\n",
    "from tqdm.notebook import tqdm \n",
    "import matplotlib.pyplot as plt\n",
    "from torchview import draw_graph\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "## ----- MISC ----- ##\n",
    "from datetime import datetime\n",
    "\n",
    "## ----- REPRODUCIBILITY ----- ##\n",
    "seed = 111\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.backends.cudnn.benchmark = False\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51670b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## -------------------------------- ##\n",
    "## HYPERPARAMETERS\n",
    "## -------------------------------- ##\n",
    "\n",
    "# Figure path\n",
    "fig_path = \"figures/\"\n",
    "if not os.path.exists(fig_path): print(\"Figure Path Does Not Exist!\")\n",
    "\n",
    "# Batch size\n",
    "batch_size = 16 #64 \n",
    "\n",
    "# Number of channels (grayscale)\n",
    "nc = 1\n",
    "\n",
    "# Size of generator input latent vector\n",
    "nz = 200\n",
    "\n",
    "# Size of feature maps in generator\n",
    "ngf = 256\n",
    "\n",
    "# Size of feature maps in discriminator\n",
    "ndf = 64\n",
    "\n",
    "# Number of training epochs\n",
    "num_epochs = 1000\n",
    "\n",
    "# Learning rate for optimizers\n",
    "lrD = 3e-4\n",
    "lrG = 3e-4\n",
    "\n",
    "# Beta1 hyperparam for Adam optimizers\n",
    "beta1 = 0.5\n",
    "\n",
    "# Number of GPUs available\n",
    "ngpu = torch.cuda.device_count()\n",
    "\n",
    "# Decide which device we want to run on\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if  torch.backends.mps.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7444fb-ffc0-425a-baef-253f0baf2d9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## -------------------------------- ##\n",
    "## USEFUL FUNCTIONS\n",
    "## -------------------------------- ##\n",
    "\n",
    "## ----- WEIGHT INITIALIZATION ----- ##\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.01)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.01)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "        \n",
    "## ----- LATENT VECTOR GENERATOR ----- ##\n",
    "latent_vec_gen = 'uniform'\n",
    "def latent_vec(device, size, gen = latent_vec_gen):\n",
    "    if gen == \"normal\":\n",
    "        return torch.randn(size, nz, 1, 1, device=0)\n",
    "    elif gen == \"uniform\":\n",
    "        return torch.distributions.Uniform(-1.0, 1.0).\\\n",
    "               sample(sample_shape=torch.Size([size, nz, 1, 1])).to(device)\n",
    "\n",
    "## ----- COUNT MODEL PARAMETERS ----- ##        \n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "## ----- HU STANDARDIZING FUNCTION ----- ##\n",
    "def standardize(slices, scalings, direction = 1):\n",
    "    if direction == 0: # FORWARDS\n",
    "        scalings.append(np.min(slices_org))\n",
    "        slices = slices_org - np.min(slices_org)     # 0 - 2500\n",
    "\n",
    "        scalings.append(np.max(slices))\n",
    "        slices = slices / np.max(slices)             # 0 - 1\n",
    "\n",
    "        scalings.extend([0.5, 0.5])\n",
    "        slices = (slices - 0.5) / 0.5                # µ = 0.5, σ = 0.5\n",
    "        return slices, scalings\n",
    "\n",
    "    elif direction == 1: # BACKWARDS\n",
    "        slices = ((slices.squeeze() * 0.5) + 0.5) * scalings[1] + scalings[0]\n",
    "        return slices\n",
    "        \n",
    "## ----- NUMPY -> TENSOR HELPERS ----- ##    \n",
    "to_t = lambda array: torch.tensor(array, device=device, dtype=torch.float32)\n",
    "from_t = lambda tensor: tensor.to('cpu').detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febf5072-77cf-4e71-97c0-a5c2797fe32b",
   "metadata": {},
   "source": [
    "## Step 2: Import Training Data\n",
    "\n",
    "We'll have to figure out what we want to do here. Maybe a dummy dataset of our toy skulls? And maybe we can include a link to the Celeb-A dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d205fe-2a8d-4d06-95a1-1ce604a7a258",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## ----- LOAD SAMPLES ----- ##\n",
    "slices_org = np.load(\"data/reals/slices_2k.npy\")[0:200]\n",
    "\n",
    "## ----- STANDARDIZE DATA ----- ##\n",
    "slices, scalings = standardize(slices_org, [], 0)\n",
    "\n",
    "print(\"Original Range:\", round(np.min(slices_org), 3), \"-\", round(np.max(slices_org), 3))\n",
    "print(\"Standardized Range:\", round(np.min(slices), 3), \"-\", round(np.max(slices), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad22202-2ffd-4ba7-819a-3b1398abcb6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## ----- DISPLAY SKULLS ----- ##\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title('Max of Real Skulls')\n",
    "plt.imshow(np.max(slices.squeeze(), axis=0), cmap='gray')\n",
    "plt.colorbar(fraction=0.046, pad=0.04)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title('Average of Real Skulls')\n",
    "plt.imshow(np.mean(slices.squeeze(), axis=0), cmap='gray')\n",
    "plt.colorbar(fraction=0.046, pad=0.04)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title('Real Skulls Sample')\n",
    "plt.imshow(slices[151].squeeze(), cmap='gray')\n",
    "plt.colorbar(fraction=0.046, pad=0.04)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97953197-e850-486a-b556-7df1a33bd92b",
   "metadata": {},
   "source": [
    "## Step 3: Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c87ab6-709e-4f31-bd96-5c78da20f569",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## ----------- DATASET ----------- ##\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image, transform=None):\n",
    "        self.image = image\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.image[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7c75ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## ----------- DATALOADER ----------- ##\n",
    "dataset = CustomDataset(to_t(slices))\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0, \n",
    "                        worker_init_fn=np.random.seed(seed))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46654cde-75ae-4588-a818-88cbf4c9eb14",
   "metadata": {},
   "source": [
    "### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503ec683",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GeneratorNoise(nn.Module):\n",
    "    def __init__(self, ngpu, upper_bound, lower_bound, std):\n",
    "        super(GeneratorNoise, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.upper_bound = upper_bound\n",
    "        self.lower_bound = lower_bound\n",
    "        self.std = std\n",
    "    \n",
    "    def forward(self, x):\n",
    "        clone = torch.clone(x)\n",
    "        channel_max = torch.amax(clone, (2, 3), True)\n",
    "        channel_min = torch.amin(clone, (2, 3), True)        \n",
    "        channel_std = torch.std(x, dim=(2, 3), keepdims=True)\n",
    "        channel_mean = torch.mean(x, dim=(2, 3), keepdims=True)\n",
    "        noise = torch.empty_like(x).normal_(mean=0.0, std=1.0).to(device)\n",
    "\n",
    "        if self.std == 'fixed':\n",
    "            channel_noise = noise\n",
    "        elif self.std == 'dynamic':\n",
    "            channel_noise = noise * channel_std\n",
    "\n",
    "        clone[clone < - channel_max / self.lower_bound] = 0        \n",
    "        clone[clone > channel_max / self.upper_bound] = 0        \n",
    "        return x + clone * channel_noise           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2bf251",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## ----------- GENERATOR ----------- ##\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Generator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main1 = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d(nz, ngf * 16, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 16),\n",
    "            nn.ReLU(True))\n",
    "            \n",
    "            # state size. 4096 x 4 x 4\n",
    "        self.main2 = nn.Sequential(            \n",
    "            nn.ConvTranspose2d(ngf * 16, ngf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),            \n",
    "            nn.ReLU(True))\n",
    "\n",
    "            # state size. 2048 x 8 x 8\n",
    "        self.main3 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True))\n",
    "            \n",
    "            # state size. 1024 x 16 x 16 \n",
    "        self.main4 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),            \n",
    "            nn.ReLU(True))\n",
    "            \n",
    "            # state size. 512 x 32 x 32\n",
    "        self.main5 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True))\n",
    "\n",
    "            # state size. 256 x 64 x 64        \n",
    "        self.main6 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(ngf, round(ngf / 2), 4, 2, 1, bias=False))\n",
    "            \n",
    "            # state size. 1 x 128 x 128\n",
    "        self.conv1 = nn.Conv2d(round(ngf / 2), round(ngf / 4), 3, 1, 1, bias=True)\n",
    "        self.conv2 = nn.Conv2d(round(ngf / 4), round(ngf / 8), 3, 1, 1, bias=True)\n",
    "        self.conv3 = nn.Conv2d(round(ngf / 8), round(ngf / 16), 3, 1, 1, bias=True)\n",
    "        self.conv4 = nn.Conv2d(round(ngf / 16), nc, 3, 1, 1, bias=False)\n",
    "        self.tanh = nn.Tanh()\n",
    " \n",
    "    def forward(self, input):\n",
    "        channel_noise_1 = GeneratorNoise(ngpu, upper_bound=4.0, lower_bound=2.0, std='dynamic')                  \n",
    "        \n",
    "        x = self.main1(input)\n",
    "        x = self.main2(x)\n",
    "        x = self.main3(x)\n",
    "        x = self.main4(x)\n",
    "        x = self.main5(x)\n",
    "        x = self.main6(x)\n",
    "        x = channel_noise_1(x)\n",
    "        x = self.conv1(x)                                    \n",
    "        x = self.conv2(x)  \n",
    "        x = channel_noise_1(x)             \n",
    "        x = self.conv3(x)      \n",
    "        x = self.conv4(x)      \n",
    "        x = self.tanh(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18646b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## ----- INIT GENERATOR ----- ##\n",
    "netG = Generator(ngpu).to(device)\n",
    "\n",
    "if torch.cuda.is_available() and ngpu > 1:\n",
    "    netG = nn.DataParallel(netG, list(range(ngpu)))\n",
    "\n",
    "## ----- INIT WEIGHTS ----- ##\n",
    "netG.apply(weights_init)\n",
    "netG = netG.float()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5940f93d-94eb-41ce-9b80-f33c51084288",
   "metadata": {},
   "source": [
    "### Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f466c9-8963-4f3a-b42f-1556a2237ee7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## ----------- DISCRIMINATOR ----------- ##\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # input is 1 x 128 x 128\n",
    "            nn.Conv2d(nc, ndf, 4, stride=2, padding=1, bias=True), \n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            # state size. 32 x 64 x 64\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, stride=2, padding=1, bias=True),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            # state size. 64 x 32 x 32     \n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, stride=2, padding=1, bias=True),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            # state size. 128 x 16 x 16      \n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, stride=2, padding=1, bias=True),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # state size. 256 x 8 x 8    \n",
    "            nn.Conv2d(ndf * 8, ndf * 16, 4, stride=2, padding=1, bias=True),\n",
    "            nn.BatchNorm2d(ndf * 16),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            # state size. 512 x 4 x 4     \n",
    "            nn.Conv2d(ndf * 16, 1, 4, stride=1, padding=0, bias=True),\n",
    "            nn.Sigmoid()\n",
    "            # state size. 1\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4a8730",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## ----- INIT DISCRIMINATOR ----- ##\n",
    "netD = Discriminator(ngpu).to(device)\n",
    "\n",
    "if torch.cuda.is_available() and ngpu > 1:\n",
    "    netD = nn.DataParallel(netD, list(range(ngpu)))\n",
    "\n",
    "## ----- INIT WEIGHTS ----- ##\n",
    "netD.apply(weights_init)\n",
    "netD = netD.float()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48258ad4-d375-489e-9087-5d8d2b580245",
   "metadata": {},
   "source": [
    "## Step 4: Load Pretrained Model (Celeb-A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0540c3-58df-46c6-9e53-196241bc3036",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## ----- LOAD PRETRAINED MODEL WEIGHTS ----- ##\n",
    "\n",
    "# Model filenames and locations\n",
    "netG_pretrained = \"models/netG_Celeb_A.pth\"\n",
    "netD_pretrained = \"models/netD_Celeb_A.pth\"\n",
    "\n",
    "# Load state dictionaries\n",
    "netG_state_dict = torch.load(netG_pretrained, map_location = device)\n",
    "netD_state_dict = torch.load(netD_pretrained, map_location = device)\n",
    "\n",
    "# Remove 'module' prefix if not using DataParallel\n",
    "netG_state_dict = {key.replace('module.', '') : value for key, value in netG_state_dict.items()}\n",
    "netD_state_dict = {key.replace('module.', '') : value for key, value in netD_state_dict.items()}\n",
    "\n",
    "# Load state dictionaries\n",
    "netG.load_state_dict(netG_state_dict)\n",
    "netD.load_state_dict(netD_state_dict)\n",
    "\n",
    "print(\"Pretrained Model Loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e16f96-ab9a-4964-9a76-cc6510d2adf9",
   "metadata": {},
   "source": [
    "## Step 5: Train SkullGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b1daa4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## ----- LOSS ----- ##\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "## ----- OPTIMIZATION ----- ##\n",
    "\n",
    "# Create fixed batch of latent vectors\n",
    "fixed_noise = latent_vec(device, batch_size, gen = latent_vec_gen)\n",
    "\n",
    "# Establish convention for real and fake labels during training\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "\n",
    "# Setup Adam optimizers for both G and D\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lrD, betas=(beta1, 0.999)) #, weight_decay=1e-5)\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lrG, betas=(beta1, 0.999)) #, weight_decay=1e-5)\n",
    "\n",
    "# Establish loss threshold for training\n",
    "threshold = 0.9\n",
    "\n",
    "# Add dynamic learning rate scheduler\n",
    "schedulerG = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizerG, mode='min', factor=0.5, patience=1000)\n",
    "schedulerD = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizerD, mode='min', factor=0.8, patience=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c284d29-ea5f-4eaf-aec8-535da05cd58e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## ----- PRINT MODEL PARAMETER COUNTS ----- ##\n",
    "print(\"Discriminator Parameter Count:\", f\"{count_parameters(netD):,}\")\n",
    "print(\"Generator Parameter Count:\", f\"{count_parameters(netG):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e8936f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## ----- PROGRESS LISTS ----- ##\n",
    "img_list = []\n",
    "corr_list = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "iters = 0\n",
    "\n",
    "## ----- DISPLAY ----- ##\n",
    "epoch_fig = plt.figure(figsize = (12, 4))\n",
    "\n",
    "pbar = tqdm(range(num_epochs))\n",
    "pbar.set_description(\"Epoch\")\n",
    "inner_pbar = tqdm(range(len(slices_org)))\n",
    "inner_pbar.set_description(\"Batch\")\n",
    "\n",
    "normalize = True\n",
    "    \n",
    "## ----- FOR EACH EPOCH ----- ##\n",
    "for epoch in pbar:\n",
    "                \n",
    "    inner_pbar.reset()\n",
    "    \n",
    "    ## ----- FOR EACH BATCH ----- ##\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        \n",
    "        ## -------------------------------------- ##\n",
    "        ## UPDATE DISCRIMINATOR:\n",
    "        ## maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ## -------------------------------------- ##\n",
    "        \n",
    "        ## ---- TRAIN WITH ALL REALS ----- ##\n",
    "        \n",
    "        # Zero gradients\n",
    "        netD.zero_grad()\n",
    "        \n",
    "        # Format batch\n",
    "        real_cpu = data.to(device)\n",
    "        b_size = real_cpu.size(0)\n",
    "        \n",
    "        # Labels\n",
    "        label_smoothing = 0.90\n",
    "        label = label_smoothing * torch.full((b_size,), real_label, dtype=torch.float32, device=device)\n",
    "        \n",
    "        # Run discriminator\n",
    "        output = netD(real_cpu).view(-1)\n",
    "    \n",
    "        # Calculate loss on all-real batch\n",
    "        errD_real = criterion(output, label.float())\n",
    "        \n",
    "        # Calculate gradients for D in backward pass\n",
    "        errD_real.backward()\n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        ## ----- TRAIN WITH FAKES & SMOOTHED REALS ----- ##\n",
    "        \n",
    "        # Generate batch of latent vectors\n",
    "        noise = latent_vec(device, b_size, gen=latent_vec_gen)\n",
    "        \n",
    "        brt = 15  # blurred reals threshold\n",
    "        if epoch <= brt:\n",
    "            fake = netG(noise)\n",
    "        elif epoch > brt and epoch <= b_size:\n",
    "            # Generate fake image batch with G\n",
    "            noise_std = max(0.5, 1.0 * brt / epoch) \n",
    "            Gauss_blur = transforms.GaussianBlur(kernel_size=3, sigma=noise_std)\n",
    "            real_blurred = Gauss_blur(next(iter(dataloader)))            \n",
    "            \n",
    "            fake = torch.cat((netG(noise)[:int(b_size-(epoch - brt)), :, :], \n",
    "                           real_blurred[:(epoch - brt), :, :]), dim=0) \n",
    "        elif epoch >= b_size:\n",
    "            fake = torch.cat((netG(noise)[:int(b_size / 2), :, :], \n",
    "                           real_blurred[:int(b_size / 2), :, :]), dim=0) \n",
    "                    \n",
    "        # Labels\n",
    "        label = torch.full((fake.size()[0],), fake_label, dtype=torch.float32, device=device)\n",
    "\n",
    "        # Classify all fake batch with D\n",
    "        output = netD(fake.detach()).view(-1)\n",
    "        \n",
    "        # Calculate D's loss on the all-fake batch\n",
    "        errD_fake = criterion(output, label.float())\n",
    "        \n",
    "        # Calculate the gradients for this batch, accumulated (summed) with previous gradients\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.mean().item()\n",
    "        \n",
    "        ## ----- UPDATE D ----- ##\n",
    "        \n",
    "        # Compute error of D as sum over the fake and the real batches\n",
    "        errD = errD_real + errD_fake\n",
    "        \n",
    "        # Step optimizer\n",
    "        if epoch < 10 or errD.item() > threshold:\n",
    "            optimizerD.step()\n",
    "        \n",
    "        # Update learning rate\n",
    "        schedulerD.step(errD)\n",
    "\n",
    "        ## -------------------------------------- ##\n",
    "        ## UPDATE GENERATOR: \n",
    "        ## maximize log(D(G(z)))\n",
    "        ## -------------------------------------- ##\n",
    "        \n",
    "        #fake = netG(noise)\n",
    "        # Zero gradients\n",
    "        netG.zero_grad()\n",
    "        \n",
    "        # fake labels are real for generator cost\n",
    "        label = torch.full((fake.size()[0],), real_label, dtype=torch.float32, device=device)\n",
    "        \n",
    "        # Since we just updated D, perform another forward pass of all-fake batch through D\n",
    "        output = netD(fake).view(-1)\n",
    "        \n",
    "        # Calculate G's loss based on this output\n",
    "        errG = criterion(output, label.float())\n",
    "        \n",
    "        # Calculate gradients for G\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        \n",
    "        ## ----- UPDATE G ----- ##\n",
    "        \n",
    "        # Update G\n",
    "        if epoch < 10 or errG.item() > threshold:            \n",
    "            optimizerG.step() \n",
    "            \n",
    "        # Update learning rate\n",
    "        schedulerG.step(errG)\n",
    "\n",
    "        ## ----- UPDATE LISTS ----- ##\n",
    "        \n",
    "        # Save Losses for plotting later\n",
    "        G_losses.append(errG.item())\n",
    "        D_losses.append(errD.item())\n",
    "    \n",
    "        if i == len(dataloader) - 1:\n",
    "            pbar.set_description(\"Epoch {:03} Loss_D: {:03} Loss_G: {:03} lrG {:.6} lrD {:.6}\" \\\n",
    "                .format(epoch, round(errD.item(),3), round(errG.item(),3), \\\n",
    "                schedulerG.optimizer.param_groups[0]['lr'], schedulerD.optimizer.param_groups[0]['lr']))     \n",
    "            \n",
    "        inner_pbar.update(batch_size)\n",
    "        \n",
    "        ## ----- UPDATE DISPLAY ----- ##\n",
    "            \n",
    "        if epoch > 0 and epoch % 5 == 0:  \n",
    "                \n",
    "            # Generate a batch of fake images\n",
    "            with torch.no_grad():\n",
    "                fake = netG(fixed_noise).detach().cpu()\n",
    "            img_list.append(vutils.make_grid(fake[0:16], padding=2, normalize=normalize))\n",
    "            \n",
    "            slices_fake_scaled = standardize(fake, scalings)\n",
    "                \n",
    "            ## ----- DISPLAY ----- ##\n",
    "            \n",
    "            display.clear_output(wait=True)\n",
    "            \n",
    "            pbar = tqdm(range(num_epochs))\n",
    "            pbar.set_description(\"Epoch\")\n",
    "            pbar.n = epoch\n",
    "            pbar.refresh()\n",
    "            \n",
    "            inner_pbar = tqdm(range(len(slices_org)))\n",
    "            inner_pbar.set_description(\"Batch\")\n",
    "                \n",
    "            ## ----- FAKE IMAGES ----- ##\n",
    "            plt.figure(epoch_fig.number)\n",
    "            plt.clf()\n",
    "            plt.subplot(1, 2, 1)\n",
    "            plt.axis(\"off\")\n",
    "            plt.title(\"Fake Images: Epoch \" + str(epoch))\n",
    "            plt.imshow(np.transpose(vutils.make_grid(fake[0:9], padding=2, \n",
    "                                                     nrow=3, normalize=normalize), (1,2,0)))\n",
    "            ## ----- LOSS ----- ##           \n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "            plt.plot(np.abs(G_losses),label=\"G\")\n",
    "            plt.plot(np.abs(D_losses),label=\"D\")\n",
    "            plt.xlabel(\"Iterations\")\n",
    "            plt.ylabel(\"Loss\")\n",
    "            plt.legend()\n",
    "            plt.tight_layout()\n",
    "            display.display(plt.gcf())\n",
    "    \n",
    "        iters += 1\n",
    "        \n",
    "    pbar.update(1)\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db692e35-e606-4c0d-a724-5ff0ccf67571",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ----- SAVE MODEL ----- ##\n",
    "\n",
    "now = datetime.now()\n",
    "torch.save(netG.state_dict(), \"models/netG_\" + str(now) + \".pth\")\n",
    "torch.save(netD.state_dict(), \"models/netD_\" + str(now) + \".pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d71bd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ----- DISPLAY LOSS OVER TIME ----- ##\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "plt.plot(np.abs(G_losses), label=\"G\")\n",
    "plt.plot(np.abs(D_losses), label=\"D\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.savefig(fig_path + \"Training_Loss.png\", dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab313b2c-7a2b-4f7f-89a7-bcd70d60bc08",
   "metadata": {},
   "source": [
    "## Step 6: Inference Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2002bb4-edee-4e98-8d93-2edac76248ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ----- SHOW FAKE IMAGES ----- ##\n",
    "\n",
    "# Number of images to generate\n",
    "nimages = 16\n",
    "\n",
    "# Generate some fake images\n",
    "with torch.no_grad():\n",
    "    fake = netG(latent_vec(device, nimages, gen=latent_vec_gen))\n",
    "\n",
    "# Create grid of images\n",
    "fake_skulls = np.transpose(vutils.make_grid(fake, padding=5, normalize=True).cpu(),(1,2,0))\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.imshow(fake_skulls, cmap = 'gray')\n",
    "plt.colorbar(location = \"bottom\", aspect = 50, pad = 0.03, label = \"HU\")\n",
    "plt.title(\"Synthetic Skull CTs\")\n",
    "plt.clim(scalings[0], scalings[1])\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(fig_path + \"Synthetic_Skull_CTs.png\", dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a95e443",
   "metadata": {},
   "source": [
    "## GPU Usage (NVIDIA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3ccdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'number of GPUs: {torch.cuda.device_count()}')\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56cd28c-acba-49f2-8903-83437c161c21",
   "metadata": {},
   "source": [
    "## Export Generated Segments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2d6942-54f1-4ae8-9a37-eca4a4f3f9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ----- EXPORT SAMPLES ----- ##\n",
    "\n",
    "# Generate first fake image batch\n",
    "test_samples = 100\n",
    "test_noise = latent_vec(device, test_samples, gen=latent_vec_gen)\n",
    "with torch.no_grad():\n",
    "    fake_slices = from_t(standardize(netG(test_noise), scalings)).squeeze()\n",
    "\n",
    "# Generate and concatenate more batches\n",
    "for i in range(9):\n",
    "    test_noise = latent_vec(device, test_samples, gen=latent_vec_gen)\n",
    "    with torch.no_grad():\n",
    "        fake_slices = np.concatenate((fake_slices, from_t(standardize(netG(test_noise), scalings)).squeeze()))\n",
    "\n",
    "np.save(\"figures/SkullGAN_Inference.npy\", fake_slices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
